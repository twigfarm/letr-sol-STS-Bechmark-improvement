# [SolProject 3ê¸°] STS ë¬¸ì¥ìœ ì‚¬ë„í‰ê°€
2022.10 ~ 2022.12 íŠ¸ìœ„ê·¸íŒœì—ì„œ ì§„í–‰í•œ SolProject3ê¸° ì¸í„´ì‰½ ìœ ì‚¬ë¬¸ì¥í‰ê°€ ë²¤ì¹˜ë§ˆí¬ ì—°êµ¬ê³¼ì œ 
<br/>
<br/>

## í•œêµ­ì–´ ë¬¸ì¥ìœ ì‚¬ë„ ë²¤ì¹˜ë§ˆí¬ ê°œì„  & ëª¨ë¸ ì„±ëŠ¥ í–¥ìƒ 
> ê¸°ì¡´ STS benchmarkì˜ ë¬¸ì œì ì„ ê°œì„ í•˜ê³  ê°œì„ ëœ ë°ì´í„°ì…‹ì„ ë°”íƒ•ìœ¼ë¡œ ëª¨ë¸ ì„±ëŠ¥í–¥ìƒ ë°©ì•ˆ ëª¨ìƒ‰ 

<br/>

## Team 
ğŸ‘¨ğŸ»â€ğŸ’» **Seo Kwang Wook**(researcher)    
ğŸ‘©ğŸ»â€ğŸ’» **Hwang Eun Hae**(researcher)    
<br/>
ğŸ§‘ğŸ»â€ğŸ« Choi Jin Hyuk (mentor)    


<br/>

## Requirements


- `torch ~=1.8.1`
- `transformers ~=4.25.1`
- `sentence-transformers ~=2.2.2`
- `datasets ~=2.7.1`


<br/>

## ì—°êµ¬ê³¼ì œ 

- ê¸°ì¡´ STS datasetì˜ ëª¨í˜¸í•œ ì ìˆ˜ì²™ë„ ì¬ì •ë¦½ ë° ì¬ë¼ë²¨ë§ 
- ë³€ê²½ëœ ë°ì´í„°ì˜ ìœ íš¨ì„± ê²€ì¦ ë° ëª¨ë¸ ì„±ëŠ¥ ê°œì„  
<br/>

## ê¸°ì¡´ í•œêµ­ì–´ STS benchmarkì˜ ë¬¸ì œì 

#### 1. KorSTS

- STS-B ì˜ì–´ ë°ì´í„°ì…‹ì„ ë²ˆì—­í•˜ì—¬ ì‚¬ìš© 
- ì› ë°ì´í„°ì˜ ë¼ë²¨ì ìˆ˜ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í–ˆê¸° ë•Œë¬¸ì— ë²ˆì—­ìœ¼ë¡œ ì¸í•´ ë°œìƒí•˜ëŠ” ë¬¸ë§¥ì  ì°¨ì´ë¥¼ ë¼ë²¨ì— ë°˜ì˜í•˜ì§€ ëª»í•¨

#### 2. KLUE-STS

- ê· ì¼í•˜ì§€ ì•Šì€ trainsetì˜ ì ìˆ˜ë¶„í¬ 
- ì˜ëª»ëœ ë²ˆì—­ìœ¼ë¡œ ìƒì„±ëœ ë°ì´í„°ë“¤ 
- ì£¼ê´€ì  íŒë‹¨ì´ ê°œì…ë˜ëŠ” ì ìˆ˜ ì²™ë„
- binaryíŒë‹¨ì— ëŒ€í•œ Fasleë¹„ìœ¨ì´ ë†’ì€ 2.0-3.5êµ¬ê°„ 
<br/>

## ì—°êµ¬1: STS annotation ì²™ë„ ì¬ì •ë¦½ ë° ì¬ë¼ë²¨ë§

#### ë¼ë²¨ ì²™ë„ì˜ ì¬ì •ë¦½ 

<img width="1329" alt="á„‰á…³á„á…³á„…á…µá†«á„‰á…£á†º 2022-12-22 á„‹á…©á„’á…® 5 46 17" src="https://user-images.githubusercontent.com/100064247/209094695-f93411db-558f-4bfb-bd46-343276df7a5b.png">
<br/>

#### ì¬ë¼ë²¨ ëŒ€ìƒ ë°ì´í„° ì„ ì • 

<img width="1195" alt="image" src="https://user-images.githubusercontent.com/100064247/209095264-b3efbdbb-ae7f-4e59-aaeb-2ac699de377d.png">
<br/>

#### trainsetì „ì²´ì— ëŒ€í•´ cross-validationì„ ì§„í–‰í•˜ì—¬ 1ì°¨ì  ì¶”ì¶œ 

<img width="999" alt="image" src="https://user-images.githubusercontent.com/100064247/209095685-1435b0ca-06e3-4d8d-ac1d-a7b21171066a.png">
<br/>

#### ì¶”ì¶œëœ ë°ì´í„°ë“¤ ì¤‘ ì˜ˆì¸¡ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì€ ë°ì´í„°ì™€ì˜ êµì§‘í•© ì¶”ì¶œ 

<img width="1026" alt="image" src="https://user-images.githubusercontent.com/100064247/209095773-0a69de24-f150-450a-84a2-04326248c39a.png">
<br/>

#### devsetê³¼ trainset í•©í•´ì„œ 500ì—¬ê°œì˜ ì¬ë¼ë²¨ ëŒ€ìƒë°ì´í„°ì— ëŒ€í•´ ë¼ë²¨ë§ ì§„í–‰ 

<img width="801" alt="image" src="https://user-images.githubusercontent.com/100064247/209095965-73aa4b47-3a53-440e-8bfd-6830eb561a7c.png">
<br/>

## ì—°êµ¬2: ë³€ê²½ëœ ë°ì´í„°ì˜ ìœ íš¨ì„±ê²€ì¦, ëª¨ë¸ ì„±ëŠ¥ê°œì„  

* ì¬ë¼ë²¨ ì´í›„ ìƒˆë¡œìš´ train/val/test set ì œì‘ 
  - 3.0ë¯¸ë§Œì˜ ë‚®ì€ ìœ ì‚¬ë„ë¼ë²¨ì€ word overlapì´ ë†’ì€ ë°ì´í„°ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨, 3.0ì´ìƒì˜ ë†’ì€ ìœ ì‚¬ë„ ë¼ë²¨ì€ word overlapì´ ë‚®ì€ ë°ì´í„°ë¥¼ ìš°ì„ ì ìœ¼ë¡œ í¬í•¨ì‹œì¼œ ëª¨ë¸ì´ word overlapê¸°ë°˜ìœ¼ë¡œ ë¬¸ì¥ìœ ì‚¬ë„ë¥¼ íŒë‹¨í•˜ëŠ” ê²½í–¥ì„±ì„ ë°˜ì˜í•˜ì§€ ì•Šë„ë¡ testsetì„ êµ¬ì„± 
 
<img width="1225" alt="image" src="https://user-images.githubusercontent.com/100064247/209096382-a8f1feb5-f2cb-451b-add5-749bf8fdb826.png">
<br/>



### Evaluate model-performance with new_devset
> how to use 


```python
! git clone https://github.com/tommyEzreal/SolProject3-STS-Bechmark-improvement
%cd /SolProject3-STS-Bechmark-improvement/model_evaluation/
%run model_evalutation.py
```
```python
# í•™ìŠµì™„ë£Œëœ model ë¶ˆëŸ¬ì˜¤ê¸° (cross-encoder)
model_save_path = ' '
model_evaluation(model_save_path ,
                 encoding ='cross-encoding')

# bi-encoder
model_save_path = ' '
model_evaluation(model_save_path ,
                 encoding ='bi-encoding')
```
<br/>

### ë³€ê²½ëœ ë°ì´í„°ì˜ ìœ íš¨ì„± ê²€ì¦ - ëª¨ë¸ì„±ëŠ¥ ë¹„êµì‹¤í—˜

#### F1-scoreì˜ ì¸¡ì • 
- 3.0labelê¸°ì¤€ìœ¼ë¡œ TRUE/FALSE

```python
def confusion_matrix(test):

  TP = len(test[test['correctness'] == 'True_P'])
  TN = len(test[test['correctness'] == 'True_N'])
  FP = len(test[test['correctness'] == 'False_P'])
  FN = len(test[test['correctness'] == 'False_N'])
  print("TP:",TP,"TN:",TN,"FP:",FP,"FN",FN)

  
  if (TP + FP) & (TP+FN) ==0:
    return("accuracy:",(TP+TN)/(TP+TN+FP+FN))
  
  else:
    pc=TP/(TP+FP)
    rc=TP/(TP+FN)
    
    return("accuracy:",(TP+TN)/(TP+TN+FP+FN),"precision:", TP/(TP+FP), "recall:", TP/(TP+FN),"f1 score:", 2*pc*rc/(pc+rc))
```

#### <ëª¨ë¸ì„ ì •>   
*all results are trained with 10random_seed and 3 epochs


- cross-encding vs bi-encoding 

|**Model** trained with|**Pearson R**|**F1 score**|**MSE**|
|------|---|---|---|
|***Bi-encoder* / *KLUE-RoBERTa-base***|||
|original klue-trainset|87.60|80.03|-|
|new trainset|88.08|80.65|-|
|***Cross-encoder* / *KLUE-RoBERTa-base***|||
|original klue-trainset|90.55|81.38|0.41|
|new trainset|**91.14**|**82.98**|**0.37**|


<br/>

- BERT / ELECTRA / RoBERTa (cross-encoder)

|**Model** trained with|**Pearson R**|**F1 score**|**MSE**|
|------|---|---|---|
|***KLUE-BERT-base***|||
|original klue-trainset|88.32|81.09|0.44|
|new trainset|89.62|80.30|0.41|
|***KoELECTRA-base***|||
|original klue-trainset|88.72|81.12|0.40|
|new trainset|90.54|**83.12**|**0.37**|
|***KLUE-RoBERTa-base***|||
|original klue-trainset|90.55|81.38|0.41|
|new trainset|**91.14**|82.98|**0.37**|

<br/>

## ë³€ê²½ëœ ë°ì´í„°ì˜ ìœ íš¨ì„± ê²€ì¦ - ìœ íš¨ì„±ê²€ì¦ ì‹¤í—˜ì„¤ê³„ 

<img width="1191" alt="image" src="https://user-images.githubusercontent.com/100064247/209103925-5fbecb1f-1980-4fb9-bf6e-8d5d81cfbd0c.png">

<br/>

### ìœ íš¨ì„±ê²€ì¦ ì‹¤í—˜ê²°ê³¼ 

|**Model** trained with|**Pearson R**|**F1 score**|**MSE**|**2.0-3.5<br/>Pearson R**|**2.0-3.5<br/>ACC**|
|---------|---|---|---|----|---|
|***KLUE-BERT-base***|||
|original klue-trainset|90.55|81.38|0.41|39.42|59.36|
|new trainset|**91.14**|**82.98**|**0.37**|**43.73**|**62.68**|


> ì „ì²´êµ¬ê°„ ì„±ëŠ¥ìƒìŠ¹ / ì¬ë¼ë²¨ë§ íƒ€ê²Ÿêµ¬ê°„ì´ì—ˆë˜ 2.0-3.5êµ¬ê°„ì˜ í”¼ì–´ìŠ¨ê³„ìˆ˜, acc ë” í°í­ìœ¼ë¡œ ìƒìŠ¹ 

<br/>

#### ëª¨ë¸ ì„±ëŠ¥ê°œì„  - semi-supervised learning 

<img width="1245" alt="image" src="https://user-images.githubusercontent.com/100064247/209106383-5998ba70-a001-4b3f-b3bc-2b9439070ce9.png">

#### ëª¨ë¸ ì„±ëŠ¥ê°œì„  - data augmentation
<img width="1265" alt="image" src="https://user-images.githubusercontent.com/100064247/209106580-85894063-31de-43ca-82f0-705fd120b418.png">

#### ëª¨ë¸ ì„±ëŠ¥ê°œì„  - augmentation range selection
<img width="1250" alt="image" src="https://user-images.githubusercontent.com/100064247/209106741-13d537de-ed67-4613-b02c-4e233d9892dc.png">

#### ëª¨ë¸ ì„±ëŠ¥ê°œì„  - pseudo-label selection
<img width="1142" alt="image" src="https://user-images.githubusercontent.com/100064247/209107009-acc1b33d-ed9f-4993-a24b-72fb3b7d404c.png">

## Label Selection (remove_uncertain_pseudo_label)
> how to use
```python
! git clone https://github.com/tommyEzreal/SolProject3-STS-Bechmark-improvement
%cd ~ /SolProject3-STS-Bechmark-improvement/label_selection/
%run remove_uncertain_label.py
```

```python
sentence_pairs = [ *unlabeled sentence pairs* ]
model_list = [ *model_save_path_1*, *model_save_path_2* , *model_save_path_3* , ... ] # trained model

remove_uncertain_label(model_list,sentence_pairs)

```



<br/>

### ëª¨ë¸ ì„±ëŠ¥ê°œì„  ì‹¤í—˜ê²°ê³¼ 
|**Model** trained with|**Pearson R**|**F1 score**|**1.8-3.2 <br/>Pearson R**|**Data<br/>Augmentation**|**Num of<br/> Augmented data**|**Aug range**|
|---------|---|---|---|----|---|---|
|***without data augmentation***||||
|original klue-trainset|90.55|81.38|39.45|x|x|x|
|new trainset|91.14|82.65|41.75|x|x|x|
|***with data augmentation***||||
|best-model predicted label|91.61|83.57|43.59|+korsts-test|485|1.8-3.2|
|ensembled label|91.98|83.24|46.44|+korsts-test|485|1.8-3.2|
|best-model predicted label|91.57|**84.04**|46.60|+korsts-test<br/>& paraKAIST|851|1.8-3.2|
|ensembled label|**92.05**|83.30|**49.53**|+korsts-test<br/>& paraKAIST|847|1.8-3.2|
> í•œê°€ì§€ ë°ì´í„°ì— ëŒ€í•´ì„œë§Œ ì¦ê°• / ìˆ˜ë¥¼ ëŠ˜ë ¤ ë‘ê°€ì§€ ëª¨ë‘ì— ëŒ€í•´ ì¦ê°•í•œ ê²½ìš° <br/> ë‘ê°€ì§€ ëª¨ë‘ ì¦ê°•ì „ë³´ë‹¤ ì„±ëŠ¥í–¥ìƒ <br/> ì•™ìƒë¸”ì„ í†µí•´ ë¶ˆí™•ì‹¤ì„±ì´ ë†’ì€ ë¼ë²¨ì„ ì œê±°í•œí›„ ë°ì´í„°ì¦ê°•ì„ ì ìš©í•œ ê²½ìš°ê°€ ë” ë†’ì€ ì„±ëŠ¥ 

<br/>

## ì—°êµ¬ ì˜ì˜ ë° í•œê³„ì  

### ì˜ì˜ 
-  ë¼ë²¨ë§ ë‚œì´ë„ê°€ ë†’ì€ ì ìˆ˜êµ¬ê°„ì˜ ëª…í™•í•œ ë¼ë²¨ë§ ê¸°ì¤€ ì •ë¦½
-  ì–‘ì§ˆì˜ STSë¼ë²¨ ë°ì´í„° ì œì‘
-  ì ì€ìˆ˜ì˜ ë¼ë²¨êµì •ê³¼ ë°ì´í„° ì¦ê°•ë§Œìœ¼ë¡œ ìœ ì˜ë¯¸í•œ ì„±ëŠ¥ë³€í™” ë„ì¶œ
-  ê¸°ì¡´ ë²¤ì¹˜ë§ˆí¬ì˜ ë¬¸ì œì ì„ êµì •í•œ ìƒˆë¡œìš´ ë²¤ì¹˜ë§ˆí¬ë¡œì˜ ë°œì „ ê°€ëŠ¥ì„±
-  ëª¨ë¸ ì„±ëŠ¥í–¥ìƒê³¼ ë°ì´í„° êµì • ë° ì¦ê°•ì„ ìœ„í•œ ë‹¤ì–‘í•œ ë°©ë²•ë¡ ì˜ ì‹œë„, ìœ ì˜ë¯¸í•œ ì‹¤í—˜ê²°ê³¼ ë„ì¶œ 

### í•œê³„ì 
- ì ì€ ì–‘ì˜ ì¬ë¼ë²¨ ë°ì´í„° 
- ë¼ë²¨ë§ ê°€ì´ë“œì˜ ë‚œì´ë„ ìƒìŠ¹ 
- í•´ê²°í•˜ì§€ ëª»í•œ ì›Œë“œ ì˜¤ë²„ë©ê¸°ë°˜ ì˜ˆì¸¡ê²½í–¥ 
- ì—¬ì „íˆ ë¶ˆê· í˜•í•œ í›ˆë ¨ë°ì´í„° 



<br/>

## Reference

### Papers
- Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks(2019)
- Augmented SBERT: Data Augmentation Method for Improving Bi-Encoders for Pairwise Sentence Scoring Tasks(2020)
- KLUE: Korean Language Understanding Evaluation(2021)
- KorNLI and KorSTS: New Benchmark Datasets for Korean Natural Language Understanding(2020)
- SemEval2017 Task 1: Semantic Textual Similarity Multilingual and Crosslingual Focused Evaluation
- A survey on semi-supervised learning(2020)
- Learning with pseudo-ensembles(2014)
- Pseudo-Labels Are All You Need(2022)
- 2021ë…„ ìœ ì‚¬ ë¬¸ì¥ ìƒì„± ë§ë­‰ì¹˜ ì—°êµ¬ ë¶„ì„ ì‚¬ì—…
- ìœ ì‚¬ë§ë­‰ì¹˜ ë¶„ì„ì„ í†µí•œ ìœ ì‚¬ë„ ì¸ì‹ì— ê´€í•œ ì—°êµ¬(2021)

### Others
- https://www.datacamp.com/tutorial/active-learning
- https://blog.est.ai/2020/11/ssl/
- https://github.com/UKPLab/sentence-transformers
- https://github.com/Huffon/klue-transformers-tutorial/blob/master/sentence_transformers.ipynb
- https://pseudo-lab.github.io/klue-baseline/docs/Semantic%20Textual%20Similarity.html
- https://www.youtube.com/watch?v=WS1uVMGhlWQ
- https://www.youtube.com/watch?v=aSx0jg9ZILo
